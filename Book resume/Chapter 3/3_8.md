## Detailed Summary of Text on Entropy, Passwords, and Partial-Guessing Metrics

### Overview
The text delves into various concepts associated with information-theoretic (Shannon) entropy, guessing entropy, and partial-guessing metrics to understand guessing attacks on user-generated passwords. It seeks to correct common misunderstandings about entropy that have historically led to flawed models and conclusions in the realm of password security.

---

### Key Concepts

#### Shannon Entropy
- **Definition**: For an event space \(X\) with \(n\) possible events, each having a probability \(q_i\), Shannon entropy \(H(X)\) is defined as:
\[
H(X) = - \sum_{i=1}^{n} q_i \cdot \log_2(q_i)
\]
- **Utility**: Measures the average uncertainty or information in \(X\), serving as a minimum number of bits needed to represent the events in \(X\).
- **Interpretation**: The lesser the probability \(q_i\) of an outcome, the more information is conveyed when that outcome occurs.

#### Properties of Shannon Entropy
1. \( H(X) \geq 0 \): Minimum entropy occurs when one event has a probability of 1.
2. \( H(X) \leq \log_2(n) \): Maximum entropy occurs when all events are equiprobable.
3. Changing probabilities to be more equal increases \(H(X)\).

#### Min-Entropy
- **Definition**: Measures the probability of the most likely event (\(q_1\)) as \(H_\infty(X) = -\log_2(q_1)\).
- In specific cases where all events are equally probable, Min-Entropy matches Shannon entropy.

#### Guesswork (Guessing Function)
- **Definition**: Given \(q_i \geq q_{i+1}\) (optimal guessing order), the average number of trials to guess a specific event in \(X\) is defined by the guesswork function \(G_1(X)\) as:
\[
G_1(X) = \sum_{i=1}^{n} i \cdot q_i
\]
- **Limitations**: The guesswork metric could be misleading when events are not equally probable, especially in the context of skewed password distributions.

---

### Practical Implications and Examples

#### Practical Shortcomings of Entropy and Guesswork Metrics
- Entropy and Guesswork metrics are not fully reflective of real-world attacks.
- They assume attackers guess through entire password spaces, whereas in reality, attackers prioritize high-probability passwords and don't always search exhaustively.
- Complete probability distributions for real-world passwords are difficult to obtain.

#### Real-World Metrics

1. **Cumulative Probability of Success (CPS)**
   - **Definition**: For \(b\) guessing trials on an account, \(CPS(b) = \sum_{i=1}^{b} q_i\).
   - **Example**: If the most popular 10,000 passwords account for 20% of all user passwords (\(CPS(10,000) = 0.20\)), an attacker can expect to succeed with 20% probability with 10,000 guesses.

2. **Guess Count**
   - (The text was cut off here, but presumably, this metric deals with the number of guesses needed for a successful attack based on real-world password distributions).

#### Application Examples
- Rolling a fair eight-sided die has 3 bits of Shannon entropy.
- A six-sided die with skewed probabilities has lower entropy than a fair six-sided die.
- In a system with 32 million users, a few hard-to-guess passwords can significantly inflate the guesswork metric, rendering it less useful for assessing the overall vulnerability of the system to attacks.

---

### Conclusion
While traditional entropy and guesswork metrics offer some insights into password security, they have limitations. Real-world attacks and user behaviors necessitate the use of more nuanced metrics like CPS and Guess Count for a comprehensive understanding of password-related vulnerabilities.
